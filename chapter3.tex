\chapter{Building the models}
\label{chapter:tools}
\section{Tools and resources}
This section describes the resources that served as a source of training data, and the tools that were used for gathering, filtering, and transforming the data, including XML-parsing, POS-tagging, lemmatization, and morphological disambiguation. It also presents two language modelling frameworks that enabled building large-scale n-gram and neural language models on consumer hardware.
\subsection{NKJP}
\label{section:nkjp}
Collecting high quality language data is a difficult task, as large and representative collections of modern texts are generally hard to obtain, if only for copyright reasons. One potential source of modern texts is obviously the Internet. However, web data can be extremely noisy and scraping and cleaning it poses a lot of challenges. Moreover, speech transcripts appear to be a more valuable source of training data in \gls{asr} applications, than written texts \cite{dziadzio2015comparison}. 
\subsection{Concraft-pl}
\subsection{SRILM}
\subsection{RNNLM}
\section{Method}
The process of building a language model can be roughly divided into two stages~--~data gathering and pre-processing and training the model.
