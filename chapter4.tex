\chapter{Results}
\label{chapter:results}
\section{Perplexity}
The perplexity values presented in Tables \ref{table:ppl_plain}-\ref{table:ppl_gnc} were calculated on a test set of 20 000 utterances taken from the transcripted proceedings of the Polish parliament. Because the models have different vocabularies, the perplexity is not comparable across different types of models. The perplexity of speech models is generally lower than the perplexity of text models, although it could have been an effect of a larger vocabulary. However, note that in case of the plain and lemma models, the perplexity of a model trained on the full corpus is consistently higher than that of a model trained on the speech corpus alone. This means that incorporating the text model actually leads to a worse model, assuming that perplexity is a valid metric in this context.    
\begin{table}[!htbp]
	\centering
	\caption{Perplexity of the plain text language model with Chen-Goodman's modified Kneser-Ney smoothing.}
	\label{table:ppl_plain}
	\begin{tabular*}{.6\linewidth}{@{\extracolsep{\fill}}l*3r}
		{}        & \multicolumn{1}{c}{text} & \multicolumn{1}{c}{speech} & \multicolumn{1}{c}{full}  \\
		\midrule
                unigrams  & 4409.47  & 3510.78 & 3767.37\\
	        bigrams   & 1380.31  & 445.76  & 458.40\\
		trigrams  & 1231.23  & 240.54  & 242.31\\
	\end{tabular*}
\end{table}

\begin{table}[!htbp]
	\centering
	\caption{Perplexity of the lemma language model with Chen-Goodman's modified Kneser-Ney smoothing.}
	\label{table:ppl_lemma}
	\begin{tabular*}{.6\linewidth}{@{\extracolsep{\fill}}l*3r}
		{}        & \multicolumn{1}{c}{text} & \multicolumn{1}{c}{speech} & \multicolumn{1}{c}{full} \\
		\midrule
		unigrams  & 1848.54  & 1296.54 & 1632.55\\
	        bigrams   & 752.39   & 306.58  & 374.01\\
                trigrams  & 712.68   & 189.37  & 226.69\\
	\end{tabular*}
\end{table}

\begin{table}[!htbp]
	\centering
	\caption{Perplexity of the POS language model with Witten-Bell smoothing.}
	\label{table:ppl_pos}
	\begin{tabular*}{.6\linewidth}{@{\extracolsep{\fill}}l*3r}
		{}        & \multicolumn{1}{c}{text} & \multicolumn{1}{c}{speech} & \multicolumn{1}{c}{full}  \\
		\midrule
		unigrams  & 11.28  & 10.42 & 10.40\\
	        bigrams   & 9.49   & 8.46  & 8.48\\
                trigrams  & 8.86   & 7.83  & 7.86\\
	\end{tabular*}
\end{table}

\begin{table}[!htbp]
	\centering
	\caption{Perplexity of the GNC language model with Good-Turing smoothing.}
	\label{table:ppl_gnc}
	\begin{tabular*}{.6\linewidth}{@{\extracolsep{\fill}}l*3r}
		{}        & \multicolumn{1}{c}{text} & \multicolumn{1}{c}{speech} & \multicolumn{1}{c}{full}  \\
		\midrule
		unigrams  & 91.88   & 83.22  & 82.49\\
	        bigrams   & 38.58   & 35.15  & 34.12\\
                trigrams  & 33.69   & 29.50  & 28.35\\
	\end{tabular*}
\end{table}

\section{WERR}
\label{section:werr}
\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{plain_werr_1.png}
	      \caption{Absolute word error reduction of the plain model (testing set 1)}
	      \label{figure:plain1}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{lemma_werr_1.png}
	      \caption{Absolute word error reduction of the lemma model (testing set 1)}
	      \label{figure:lemmy1}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{pos_werr_1.png}
	      \caption{Absolute word error reduction of the pos model (testing set 1)}
	      \label{figure:pos1}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{gnc_werr_1.png}
	      \caption{Absolute word error reduction of the gnc model (testing set 1)}
	      \label{figure:gnc1}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{plain_werr_5.png}
	      \caption{Absolute word error reduction of the plain model (testing set 5)}
	      \label{figure:plain5}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{lemma_werr_5.png}
	      \caption{Absolute word error reduction of the lemma model (testing set 5)}
	      \label{figure:lemmy5}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{pos_werr_5.png}
	      \caption{Absolute word error reduction of the pos model (testing set 5)}
	      \label{figure:pos5}
\end{figure}

\begin{figure}[!htbp]
	  \centering
	  \includegraphics[height=10cm, width=15cm]{gnc_werr_5.png}
	      \caption{Absolute word error reduction of the gnc model (testing set 5)}
	      \label{figure:gnc5}
\end{figure}
